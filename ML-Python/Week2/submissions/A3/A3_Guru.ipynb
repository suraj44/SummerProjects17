{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generalized Linear Model\n",
    "4 Features ==> 1 Target\n",
    "\n",
    "Employs Gradient Descent\n",
    "\n",
    "It works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string as str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x ==> Array of Feature Values\n",
    "\n",
    "x[1] returns a column of training values for the second feature\n",
    "\n",
    "y ==> Result Array. The values the Hypothesis fn should train to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('train_data.csv',header = 0)\n",
    "\n",
    "y = train_data[\"Target\"]\n",
    "y = y.values #convert to ndarray\n",
    "\n",
    "train_data = train_data.drop(\"Target\",1)\n",
    "x = train_data.values\n",
    "\n",
    "x = np.c_[np.ones(x.shape[0]),x]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calculateCost (HypothesisFn,y,x):\n",
    "    distance = HypothesisFn - y\n",
    "    return (np.sum((distance)**2)/(2*distance.size))\n",
    "\n",
    "def derivativeOf(HypothesisFn,y,x):\n",
    "    distance = HypothesisFn - y\n",
    "    deriv = np.dot(x.transpose(), distance)\n",
    "    deriv /= y.shape[0]\n",
    "    return deriv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Parameters = np.zeros(5) #initialize parameters\n",
    "HypothesisFn = np.dot(x,Parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If anyone's wondering why I didn't transpose my Parameters array, one dimensional arrays do not need to be transposed to be multiplied. np.dot figures it out on its own. \n",
    "\n",
    "np.dot is the real bae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "LearningRate = 0.1\n",
    "while True:\n",
    "    Parameters = Parameters - LearningRate*derivativeOf(HypothesisFn,y,x)\n",
    "    HypothesisFn = np.dot(x,Parameters)\n",
    "    cost = calculateCost (HypothesisFn,y,x)\n",
    "    if ( cost <= 10**(-25)):\n",
    "        break\n",
    "\n",
    "# 10^-25 seems pretty negligible. = ¯\\_(ツ)_/¯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The Hypothesis function is 1.66824986311  + 0.718373369387x1  + 3.12743084282x2  + 0.425062365086x3  + 1.21521720264x4\n"
     ]
    }
   ],
   "source": [
    "print (\"\\nThe Hypothesis function is {0}\".format(Parameters[0])),\n",
    "for i in range(1,Parameters.size):\n",
    "    print (\" + {0}x{1}\".format(Parameters[i],i)),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Variable 1  Variable 2  Variable 3  Variable 4  Prediction\n",
      "0     0.052917    0.315560    0.769792    0.242442    3.314985\n",
      "1     0.736748    0.774736    0.991972    0.686699    5.876583\n",
      "2     0.072012    0.649908    0.472070    0.879730    5.022247\n",
      "3     0.564943    0.859830    0.764108    0.991852    6.293258\n",
      "4     0.913741    0.827315    0.411412    0.885002    6.162375\n",
      "5     0.183902    0.559515    0.327523    0.730312    4.576910\n",
      "6     0.263851    0.968906    0.487362    0.949212    6.248639\n",
      "7     0.567881    0.254971    0.942230    0.814473    4.263874\n",
      "8     0.324696    0.158970    0.227014    0.410909    2.994508\n",
      "9     0.280444    0.200198    0.964338    0.860580    3.951514\n",
      "10    0.185000    0.651180    0.022720    0.722323    4.725106\n",
      "11    0.344684    0.843482    0.647393    0.331496    5.231817\n",
      "12    0.224112    0.570966    0.137944    0.880133    4.743091\n",
      "13    0.585966    0.794656    0.742884    0.587200    5.603770\n",
      "14    0.455460    0.199887    0.237061    0.948117    3.873507\n",
      "15    0.145781    0.976496    0.706553    0.466245    5.693815\n",
      "16    0.105116    0.285242    0.265898    0.406501    3.242849\n",
      "17    0.982609    0.911043    0.358867    0.617593    6.126405\n",
      "18    0.999271    0.755277    0.886075    0.937326    6.263868\n",
      "19    0.647837    0.140072    0.893775    0.319280    3.339608\n",
      "20    0.793952    0.369704    0.355454    0.814200    4.535348\n",
      "21    0.381051    0.409095    0.565238    0.763939    4.390016\n",
      "22    0.845477    0.787822    0.267364    0.379387    5.314161\n",
      "23    0.067374    0.751306    0.175546    0.874231    5.203306\n",
      "24    0.736657    0.071955    0.139063    0.431615    3.006095\n",
      "25    0.350636    0.682030    0.389500    0.554403    4.892420\n",
      "26    0.859244    0.642913    0.882985    0.492440    5.269921\n",
      "27    0.139187    0.800644    0.774105    0.348804    5.025113\n",
      "28    0.476021    0.076429    0.834784    0.035051    2.646669\n",
      "29    0.325099    0.658965    0.566500    0.760976    5.128210\n",
      "30    0.961533    0.838505    0.256368    0.152980    5.276231\n",
      "31    0.338888    0.877312    0.968079    0.862380    6.114902\n",
      "32    0.058088    0.553975    0.319993    0.941502    4.722646\n",
      "33    0.736978    0.852461    0.824838    0.671308    6.030080\n",
      "34    0.405489    0.969086    0.440965    0.673975    5.996756\n",
      "35    0.206186    0.528878    0.995515    0.588026    4.608132\n",
      "36    0.880115    0.573087    0.452686    0.708280    5.145927\n",
      "37    0.631965    0.321172    0.058512    0.331713    3.554654\n",
      "38    0.175711    0.510245    0.057679    0.116826    3.556717\n",
      "39    0.571311    0.679296    0.973027    0.930148    5.747043\n",
      "40    0.057735    0.968774    0.828177    0.692998    5.933670\n",
      "41    0.855015    0.099155    0.384450    0.534479    3.405493\n",
      "42    0.909414    0.607041    0.054595    0.544184    4.904533\n",
      "43    0.755819    0.766392    0.591364    0.985343    6.056822\n",
      "44    0.094780    0.330283    0.657516    0.860141    4.094019\n",
      "45    0.959639    0.916353    0.991050    0.368245    6.092215\n",
      "46    0.996029    0.020010    0.099648    0.824563    3.490729\n",
      "47    0.193439    0.621190    0.076266    0.667906    4.594009\n",
      "48    0.234836    0.464753    0.341920    0.218517    3.701314\n",
      "49    0.311490    0.920181    0.707429    0.134068    5.233442\n",
      "50    0.265221    0.954385    0.303192    0.539907    5.628531\n",
      "51    0.574388    0.863050    0.580298    0.534555    5.676266\n",
      "52    0.351915    0.775155    0.196954    0.305331    4.800062\n",
      "53    0.260872    0.519215    0.598623    0.802096    4.708636\n",
      "54    0.697415    0.687054    0.268074    0.721872    5.309147\n",
      "55    0.133789    0.918394    0.019873    0.308387    5.019777\n",
      "56    0.712013    0.727818    0.568780    0.800287    5.670229\n",
      "57    0.263746    0.758232    0.820299    0.302350    4.945134\n",
      "58    0.493948    0.613297    0.216240    0.029928    4.069417\n",
      "59    0.919843    0.714592    0.973155    0.470763    5.549610\n"
     ]
    }
   ],
   "source": [
    "test_input = pd.read_csv('test_input.csv',header = 0)\n",
    "test_input = test_input.values\n",
    "test_input = np.c_[np.ones(test_input.shape[0]),test_input]\n",
    "\n",
    "prediction = np.dot (test_input, Parameters)\n",
    "\n",
    "test_input = np.delete(test_input, (0), axis=1)\n",
    "test_input = np.c_[test_input,prediction]\n",
    "\n",
    "output = pd.DataFrame(data=test_input, columns = [\"Variable 1\",\"Variable 2\",\"Variable 3\",\"Variable 4\",\"Prediction\"])\n",
    "output.to_csv('test_output.csv', index=False, header=True, sep=',')\n",
    "print output #Boom shakalaka"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
